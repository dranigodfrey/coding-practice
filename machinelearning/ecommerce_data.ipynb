{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b819e03b-00e3-416b-8d5f-03c0d1ea58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a9a778b-5f42-45e9-9f63-7792335b2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preserve original data\n",
    "raw_df = pd.read_csv('orders_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abcafde2-ce83-43fd-855d-2b81a974ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a working copy\n",
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f111394-ac62-40b8-aa63-d34324d68497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Document initial state\n",
    "cleaning_log = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'original_shape': df.shape,\n",
    "    'original_columns': list(df.columns),\n",
    "    'steps': []\n",
    "}\n",
    "\n",
    "def log_step(description, changes):\n",
    "    cleaning_log['steps'].append({\n",
    "        'step': len(cleaning_log['steps']) + 1,\n",
    "        'description': description,\n",
    "        'changes': changes,\n",
    "        'shape_after': df.shape\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54a672dd-a0ff-445f-bd7d-1f6c9fa7266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Fix structural issues\n",
    "# Convert order_date to datetime with mixed format handling\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], format='mixed')\n",
    "\n",
    "log_step(\n",
    "    \"Converted order_date to datetime\",\n",
    "    {\"mixed_formats_handled\": True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44006d2a-a61b-4530-a551-ae701563f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    " #5. Handle missing values\n",
    "missing_report = df.isnull().sum().to_dict()\n",
    "\n",
    "# Customer ID - create placeholder for anonymous customers\n",
    "df['customer_id'] = df['customer_id'].fillna('ANON-' +  (df['order_id'].astype(str).str[1:].str.zfill(3)))\n",
    "\n",
    "# Discount - convert empty to 0 and remove %\n",
    "df['discount'] = df['discount'].str.rstrip('%').fillna('0').astype(float) / 100\n",
    "\n",
    "# Shipping city - fill with 'Unknown'\n",
    "df['shipping_city'] = df['shipping_city'].fillna('Unknown')\n",
    "\n",
    "log_step(\n",
    "    \"Handled missing values\",\n",
    "    {\n",
    "        'missing_customer_ids_replaced': missing_report['customer_id'],\n",
    "        'missing_discounts_set_to_zero': missing_report['discount'],\n",
    "        'missing_cities_marked_unknown': missing_report['shipping_city']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a0f3f69-c013-4c42-aff8-b9e70e4fb719",
   "metadata": {},
   "outputs": [],
   "source": [
    " #6. Standardize values\n",
    "# Convert product names to title case\n",
    "df['product'] = df['product'].str.title()\n",
    "\n",
    "# Standardize city names\n",
    "city_mapping = {'NYC': 'New York', 'SF': 'San Francisco'}\n",
    "df['shipping_city'] = df['shipping_city'].replace(city_mapping)\n",
    "\n",
    "# Standardize status to lowercase\n",
    "df['order_status'] = df['order_status'].str.lower()\n",
    "\n",
    "log_step(\n",
    "    \"Standardized values\",\n",
    "    {\n",
    "        'products_title_cased': True,\n",
    "        'city_names_standardized': list(city_mapping.keys()),\n",
    "        'status_lowercased': True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea162a10-9477-4333-b551-b2282a2ed3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Validate and correct data types\n",
    "# Ensure quantity is integer\n",
    "df['quantity'] = pd.to_numeric(df['quantity'], downcast='integer')\n",
    "\n",
    "# Ensure price is float\n",
    "df['price'] = pd.to_numeric(df['price'], downcast='float')\n",
    "\n",
    "log_step(\n",
    "    \"Validated data types\",\n",
    "    {\n",
    "        'quantity_type': str(df['quantity'].dtype),\n",
    "        'price_type': str(df['price'].dtype)\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af369eb7-a1dc-4838-bc69-69b019e9733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Detect and handle outliers\n",
    "# Calculate order totals\n",
    "df['order_total'] = df['quantity'] * df['price'] * (1 - df['discount'])\n",
    "\n",
    "# Flag potential outliers (orders over $5000)\n",
    "df['is_outlier'] = df['order_total'] > 5000\n",
    "\n",
    "log_step(\n",
    "    \"Identified outliers\",\n",
    "    {\n",
    "        'outliers_found': df['is_outlier'].sum(),\n",
    "        'outlier_threshold': 5000\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0605cbaa-cfa1-4a55-8204-5c17c10ac552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Create derived features\n",
    "# Extract order day of week\n",
    "df['order_dow'] = df['order_date'].dt.day_name()\n",
    "\n",
    "# Create customer segment based on order total\n",
    "df['customer_segment'] = pd.cut(\n",
    "    df.groupby('customer_id')['order_total'].transform('sum'),\n",
    "    bins=[-1, 500, 2000, float('inf')],\n",
    "    labels=['low', 'medium', 'high']\n",
    ")\n",
    "\n",
    "log_step(\n",
    "    \"Created derived features\",\n",
    "    {\n",
    "        'features_added': ['order_dow', 'customer_segment']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f597d5c8-550d-48aa-b0c8-2bb417ffdd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 10. Final validation\n",
    "# Check for duplicates\n",
    "duplicate_orders = df.duplicated(subset=['order_id']).sum()\n",
    "\n",
    "# Check for negative values\n",
    "negative_prices = (df['price'] < 0).sum()\n",
    "negative_quantities = (df['quantity'] < 0).sum()\n",
    "\n",
    "validation_report = {\n",
    "    'duplicate_orders': duplicate_orders,\n",
    "    'negative_prices': negative_prices,\n",
    "    'negative_quantities': negative_quantities\n",
    "}\n",
    "\n",
    "log_step(\n",
    "    \"Performed final validation\",\n",
    "    validation_report\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2789f2cf-7b8b-4ce8-9cd5-e09db2cd583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete!\n",
      "Original shape: (10, 9)\n",
      "Final shape: (10, 13)\n"
     ]
    }
   ],
   "source": [
    "# 11. Save cleaned data and log\n",
    "df.to_csv('orders_cleaned.csv', index=False)\n",
    "\n",
    "# with open('cleaning_log.json') as f:\n",
    "#     json.dumps(cleaning_log, indent=2)\n",
    "\n",
    "print(\"Data cleaning complete!\")\n",
    "print(f\"Original shape: {cleaning_log['original_shape']}\")\n",
    "print(f\"Final shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4789523-79b0-4e27-b67c-3c780d611eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
